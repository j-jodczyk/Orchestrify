{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Experiments with AI Guru and MMM_API mix\n",
    "\n",
    "The following notebook contains code for:\n",
    "- using miditok.MMM to create tokenizer\n",
    "- using AI Guru's solution to tokenize database (and create tokenizer config)\n",
    "- using AI Guru's tokenizer with original model to try and create a midi file (unsucessfully)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training the tokenizer and tokenizing the database "
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T08:02:22.786232Z",
     "start_time": "2024-11-20T08:02:22.774593Z"
    }
   },
   "source": [
    "import torch\n",
    "MODEL_PATH = \"../models/model.pt\"\n",
    "model = torch.jit.load(MODEL_PATH)"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m      2\u001B[0m MODEL_PATH \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../models/model.pt\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      3\u001B[0m model \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mjit\u001B[38;5;241m.\u001B[39mload(MODEL_PATH)\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'torch'"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T08:02:22.823728Z",
     "start_time": "2024-11-20T08:02:22.816068Z"
    }
   },
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import Trainer, TrainingArguments"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DataCollatorWithPadding\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Trainer, TrainingArguments\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'transformers'"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Loading hugging face token"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import configparser\n",
    "\n",
    "config = configparser.RawConfigParser()\n",
    "config.read('../local_config.cfg')\n",
    "\n",
    "tokens = dict(config.items('TOKENS'))\n",
    "hf_token = tokens[\"hf_token\"]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Training miditok.MMM tokenizer and pushing it to hf"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T08:02:22.839839Z",
     "start_time": "2024-11-20T08:02:22.830836Z"
    }
   },
   "source": [
    "import miditok\n",
    "from miditok.pytorch_data import DatasetMIDI, DataCollator\n",
    "from miditok.utils import split_files_for_training\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "\n",
    "config = miditok.TokenizerConfig()\n",
    "config.additional_params = { \"base_tokenizer\" : 'MIDILike' }\n",
    "\n",
    "tokenizer = miditok.MMM(config)\n",
    "\n",
    "midi_paths = list(Path(\"/home/julia/WIMU/Orchestrify/data/external/Jazz Midi\").glob(\"**/*.mid\"))\n",
    "tokenizer.train(vocab_size=512, files_paths=midi_paths)\n",
    "tokenizer.save_params(Path(\"models\", \"tokenizer.json\"))\n",
    "\n",
    "tokenizer.push_to_hub(\"juleczka/orchestrify_tokenizer\", private=True, token=hf_token)"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'miditok'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmiditok\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmiditok\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpytorch_data\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DatasetMIDI, DataCollator\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmiditok\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m split_files_for_training\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'miditok'"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Dividing dataset into chunks, creating collator and dataloader"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T08:02:22.840659Z",
     "start_time": "2024-11-20T08:02:22.840606Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset_chunks_dir = Path(\"/home/julia/WIMU/Orchestrify/data/processed\")\n",
    "split_files_for_training(\n",
    "    files_paths=midi_paths,\n",
    "    tokenizer=tokenizer,\n",
    "    save_dir=dataset_chunks_dir,\n",
    "    max_seq_len=1024,\n",
    ")\n",
    "\n",
    "# Create a Dataset, a DataLoader and a collator to train a model\n",
    "dataset = DatasetMIDI(\n",
    "    files_paths=list(dataset_chunks_dir.glob(\"**/*.mid\")),\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_len=1024,\n",
    "    bos_token_id=tokenizer[\"BOS_None\"],\n",
    "    eos_token_id=tokenizer[\"EOS_None\"],\n",
    ")\n",
    "collator = DataCollator(tokenizer.pad_token_id, copy_inputs_as_labels=True)\n",
    "dataloader = DataLoader(dataset, batch_size=64, collate_fn=collator)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Using AI Guru version"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "!pip3 install music21 > /dev/null 2>&1",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "import datasetcreatorconfig\n",
    "import datasetcreator"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T08:02:22.867622Z",
     "start_time": "2024-11-20T08:02:22.860296Z"
    }
   },
   "source": [
    "dataset_creator_config = datasetcreatorconfig.JSBDatasetCreatorTrackConfig()\n",
    "dataset_creator = datasetcreator.DatasetCreator(dataset_creator_config)\n",
    "dataset_creator.create(datasets_path='../data/external/Jazz Midi', overwrite=False)\n"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datasetcreatorconfig' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m dataset_creator_config \u001B[38;5;241m=\u001B[39m \u001B[43mdatasetcreatorconfig\u001B[49m\u001B[38;5;241m.\u001B[39mJSBDatasetCreatorTrackConfig()\n\u001B[1;32m      2\u001B[0m dataset_creator \u001B[38;5;241m=\u001B[39m datasetcreator\u001B[38;5;241m.\u001B[39mDatasetCreator(dataset_creator_config)\n\u001B[1;32m      3\u001B[0m dataset_creator\u001B[38;5;241m.\u001B[39mcreate(datasets_path\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../data/external/Jazz Midi\u001B[39m\u001B[38;5;124m'\u001B[39m, overwrite\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'datasetcreatorconfig' is not defined"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "from transformers import PreTrainedTokenizerFast",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T08:02:22.908871Z",
     "start_time": "2024-11-20T08:02:22.872318Z"
    }
   },
   "source": [
    "from torch.utils.data.dataset import Dataset\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "class TokenSequenceDataset(Dataset):\n",
    "\n",
    "    def __init__(self, tokenizer, dataset_paths, block_size, simulate=False):\n",
    "\n",
    "        pad_token_id = tokenizer.encode(\"[PAD]\")[0]\n",
    "        unk_token_id = tokenizer.encode(\"[UNK]\")[0]\n",
    "\n",
    "        # Read all lines from all files.\n",
    "        lines = []\n",
    "        for dataset_path in dataset_paths:\n",
    "            assert os.path.isfile(dataset_path), f\"Input file path {dataset_path} not found\"\n",
    "            lines += open(dataset_path, \"r\").readlines()\n",
    "\n",
    "        # In simulation just use a few samples.\n",
    "        if simulate:\n",
    "            random.shuffle(lines)\n",
    "            lines = lines[:10]\n",
    "\n",
    "        # Turn lines into training examples. Also gather some statistics.\n",
    "        self.examples = []\n",
    "        unknown_tokens_set = []\n",
    "        unknown_tokens = []\n",
    "        tokens_count = 0\n",
    "        unknown_token_lines_count = 0\n",
    "        too_long_lines_count = 0\n",
    "        encoded_lengths = []\n",
    "        for line in lines:\n",
    "\n",
    "            #Skip empty lines.\n",
    "            line = line.strip()\n",
    "            if line == \"\":\n",
    "                continue\n",
    "\n",
    "            # Encode the line.\n",
    "            encoded_line = tokenizer.encode(line)\n",
    "            encoded_lengths += [len(encoded_line)]\n",
    "            tokens_count += len(encoded_line)\n",
    "\n",
    "            # Create a warning about unknown tokens. And then skip the line.\n",
    "            if unk_token_id in encoded_line:\n",
    "                index = encoded_line.index(unk_token_id)\n",
    "                token = tokenizer.decode(encoded_line[index])\n",
    "                token = line.split()[index]\n",
    "                if token not in unknown_tokens_set:\n",
    "                    unknown_tokens_set += [token]\n",
    "                #logger.warning(f\"Skipping line because of unknown token {token}\")\n",
    "                unknown_tokens += [token]\n",
    "                unknown_token_lines_count += 1\n",
    "                continue\n",
    "\n",
    "            # Skip sequence if it is too long.\n",
    "            if len(encoded_line) > block_size:\n",
    "                #logger.warning(f\"Skipping line because it is too long... {len(encoded_line)} > {block_size}\")\n",
    "                too_long_lines_count += 1\n",
    "                continue\n",
    "\n",
    "            # Pad and truncate.\n",
    "            tensor = np.full((block_size,), pad_token_id, dtype=np.longlong)\n",
    "            tensor[:len(encoded_line)] = encoded_line\n",
    "            assert len(tensor) == block_size\n",
    "\n",
    "            self.examples += [{\n",
    "                \"input_ids\": torch.tensor(tensor, dtype=torch.long),\n",
    "                \"labels\": torch.tensor(tensor, dtype=torch.long)\n",
    "            }]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.examples[i]"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdataset\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Dataset\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mrandom\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'torch'"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Using the pretrained tokenizer"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "output_path = './models_2'\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast(tokenizer_file='../data/external/Jazz Midi/jsb_mmmtrack/tokenizer.json')\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=os.path.join(output_path),\n",
    "    overwrite_output_dir=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    num_train_epochs=10,\n",
    "    per_gpu_train_batch_size=16,\n",
    "    save_steps=1_000,\n",
    "    save_total_limit=2,\n",
    "    prediction_loss_only=False,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_dir=os.path.join(output_path, \"logs\"),\n",
    "    load_best_model_at_end=True,\n",
    "    save_strategy=\"steps\"\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorWithPadding(\n",
    "    tokenizer=tokenizer,\n",
    "    padding=\"max_length\",\n",
    "    max_length=768\n",
    ")\n",
    "\n",
    "dataset_train = TokenSequenceDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    dataset_paths=['../data/external/Jazz Midi/jsb_mmmtrack/token_sequences_train.txt'],\n",
    "    block_size=768,\n",
    "    simulate=False\n",
    ")\n",
    "\n",
    "dataset_valid = TokenSequenceDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    dataset_paths=['../data/external/Jazz Midi/jsb_mmmtrack/token_sequences_valid.txt'],\n",
    "    block_size=768,\n",
    "    simulate=False\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "dataloader = DataLoader(dataset_valid, batch_size=16, collate_fn=data_collator)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Attempt to generate midi using original model\n",
    "\n",
    "The code below uses AI Guru's tokenization with the original model. It succeeds in producing an output, however, the tokens are nonsense - after rendering back to midi we get a second of silence."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# see model's structure - it takes 2 arguments\n",
    "print(model.code)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# take one batch from loader\n",
    "batch = next(iter(dataloader))\n",
    "input_ids = batch['input_ids']\n",
    "input_ids.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Initialize `argument_2` with empty tensors\n",
    "# The dimensions and data types here are based on your model's expected format\n",
    "batch = next(iter(dataloader))\n",
    "input_ids = batch['input_ids']\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# TODO: \n",
    "batch_size = input_ids.size(0)\n",
    "num_heads = 8           # No idea what this values actually are\n",
    "hidden_dim = 512        # But they do produce the right size of argument_2 values\n",
    "sequence_length = input_ids.size(1)\n",
    "\n",
    "past_key_values = tuple(\n",
    "    (\n",
    "        torch.zeros((batch_size, num_heads, sequence_length, hidden_dim // num_heads), dtype=torch.float32).to(device),  # past_key\n",
    "        torch.zeros((batch_size, num_heads, sequence_length, hidden_dim // num_heads), dtype=torch.float32).to(device)   # past_value\n",
    "    )\n",
    "    for _ in range(6)  # Six layers, assuming GPT-2 small\n",
    ")\n",
    "\n",
    "generated_sequence = [[] for _ in range(batch_size)]\n",
    "\n",
    "# Define generation parameters\n",
    "max_length = 50\n",
    "temperature = 1.11835682 # just anything to push forward - taken from one of API tests\n",
    "\n",
    "with torch.no_grad():\n",
    "    for _ in range(max_length):\n",
    "        # Pass the current input and past states to the model\n",
    "        # from MMM_API:\n",
    "        # auto outputs = model->forward(inputs).toTuple();\n",
    "        # logits = outputs->elements()[0].toTensor().index(\n",
    "        #   {torch::indexing::Slice(),-1,torch::indexing::Slice()});\n",
    "        # past_key_values = outputs->elements()[1];\n",
    "        logits, past_key_values = model(input_ids, past_key_values)\n",
    "        logits = logits[:,-1,:]\n",
    "        # auto probs = (logits / param->temperature()).softmax(1);\n",
    "        # auto next_tokens = probs.multinomial(1);\n",
    "        probs = (logits / temperature).softmax(dim=1)\n",
    "        next_tokens = probs.multinomial(1);\n",
    "        # inputs.clear();\n",
    "        # inputs.push_back( next_tokens );\n",
    "        # inputs.push_back( past_key_values );\n",
    "        input_ids = next_tokens\n",
    "\n",
    "        for i in range(len(generated_sequence)):\n",
    "            generated_sequence[i].append(next_tokens[i, 0].item())\n",
    "\n",
    "\n",
    "# Print the generated token IDs\n",
    "print(\"Generated sequence:\", generated_sequence)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T08:02:22.922429Z",
     "start_time": "2024-11-20T08:02:22.914774Z"
    }
   },
   "source": [
    "tracks = [tokenizer.decode(generated_sequence[i]) for i in range(len(generated_sequence))]"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generated_sequence' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m tracks \u001B[38;5;241m=\u001B[39m [tokenizer\u001B[38;5;241m.\u001B[39mdecode(generated_sequence[i]) \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(\u001B[43mgenerated_sequence\u001B[49m))]\n",
      "\u001B[0;31mNameError\u001B[0m: name 'generated_sequence' is not defined"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "!pip3 install note_seq"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T08:02:22.954716Z",
     "start_time": "2024-11-20T08:02:22.934210Z"
    }
   },
   "source": [
    "BAR_LENGTH_120BPM = 4.0 * 60 / 120\n",
    "NOTE_LENGTH_16TH_120BPM = 0.25 * 60 / 120\n",
    "\n",
    "import note_seq\n",
    "\n",
    "def empty_note_sequence(qpm=120.0, total_time=0.0):\n",
    "    note_sequence = note_seq.protobuf.music_pb2.NoteSequence()\n",
    "    note_sequence.tempos.add().qpm = qpm\n",
    "    note_sequence.ticks_per_quarter = note_seq.constants.STANDARD_PPQ\n",
    "    note_sequence.total_time = total_time\n",
    "    return note_sequence\n",
    "\n",
    "def token_sequence_to_note_sequence(token_sequence, use_program=True, use_drums=True):\n",
    "\n",
    "    if isinstance(token_sequence, str):\n",
    "        token_sequence = token_sequence.split()\n",
    "\n",
    "    note_sequence = empty_note_sequence()\n",
    "    current_program = 1\n",
    "    current_is_drum = False\n",
    "    for token_index, token in enumerate(token_sequence):\n",
    "\n",
    "        if token == \"PIECE_START\":\n",
    "            pass\n",
    "        elif token == \"PIECE_END\":\n",
    "            print(\"The end.\")\n",
    "            break\n",
    "        elif token == \"TRACK_START\":\n",
    "            current_bar_index = 0\n",
    "            pass\n",
    "        elif token == \"TRACK_END\":\n",
    "            pass\n",
    "        elif token.startswith(\"INST\"):\n",
    "            current_instrument = token.split(\"=\")[-1]\n",
    "            if current_instrument != \"DRUMS\" and use_program:\n",
    "                current_instrument = int(current_instrument)\n",
    "                current_program = int(current_instrument)\n",
    "                current_is_drum = False\n",
    "            if current_instrument == \"DRUMS\" and use_drums:\n",
    "                current_instrument = 0\n",
    "                current_program = 0\n",
    "                current_is_drum = True\n",
    "        elif token == \"BAR_START\":\n",
    "            current_time = current_bar_index * BAR_LENGTH_120BPM\n",
    "            current_notes = {}\n",
    "        elif token == \"BAR_END\":\n",
    "            current_bar_index += 1\n",
    "            pass\n",
    "        elif token.startswith(\"NOTE_ON\"):\n",
    "            pitch = int(token.split(\"=\")[-1])\n",
    "            note = note_sequence.notes.add()\n",
    "            note.start_time = current_time\n",
    "            note.end_time = current_time + 4 * NOTE_LENGTH_16TH_120BPM\n",
    "            note.pitch = pitch\n",
    "            note.instrument = int(current_instrument)\n",
    "            note.program = current_program\n",
    "            note.velocity = 80\n",
    "            note.is_drum = current_is_drum\n",
    "            current_notes[pitch] = note\n",
    "        elif token.startswith(\"NOTE_OFF\"):\n",
    "            pitch = int(token.split(\"=\")[-1])\n",
    "            if pitch in current_notes:\n",
    "                note = current_notes[pitch]\n",
    "                note.end_time = current_time\n",
    "        elif token.startswith(\"TIME_DELTA\"):\n",
    "            delta = float(token.split(\"=\")[-1]) * NOTE_LENGTH_16TH_120BPM\n",
    "            current_time += delta\n",
    "        elif token.startswith(\"DENSITY=\"):\n",
    "            pass\n",
    "        elif token == \"[PAD]\":\n",
    "            pass\n",
    "        else:\n",
    "            assert False, token\n",
    "\n",
    "    return note_sequence"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'note_seq'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m BAR_LENGTH_120BPM \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m4.0\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m60\u001B[39m \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m120\u001B[39m\n\u001B[1;32m      2\u001B[0m NOTE_LENGTH_16TH_120BPM \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.25\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m60\u001B[39m \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m120\u001B[39m\n\u001B[0;32m----> 4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnote_seq\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mempty_note_sequence\u001B[39m(qpm\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m120.0\u001B[39m, total_time\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.0\u001B[39m):\n\u001B[1;32m      7\u001B[0m     note_sequence \u001B[38;5;241m=\u001B[39m note_seq\u001B[38;5;241m.\u001B[39mprotobuf\u001B[38;5;241m.\u001B[39mmusic_pb2\u001B[38;5;241m.\u001B[39mNoteSequence()\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'note_seq'"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "tracks"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "song = token_sequence_to_note_sequence(tracks)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
